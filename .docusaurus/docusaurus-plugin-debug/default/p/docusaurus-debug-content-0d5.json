{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Hackathon-book-main\\docs\\sidebar.js","contentPath":"C:\\Hackathon-book-main\\docs","docs":[{"id":"intro","title":"Introduction","description":"This book introduces you to the core concepts of modern robotics and AI systems.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Introduction"},"sidebar":"tutorialSidebar","next":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"}},{"id":"module-1/chapter-1-core-concepts","title":"Chapter 1: Core ROS 2 Concepts","description":"This chapter covers the fundamental concepts of the Robot Operating System (ROS) 2.","source":"@site/docs/module-1/chapter-1-core-concepts.md","sourceDirName":"module-1","slug":"/module-1/chapter-1-core-concepts","permalink":"/docs/module-1/chapter-1-core-concepts","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-1/chapter-1-core-concepts.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/docs/intro"},"next":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"}},{"id":"module-1/chapter-2-rclpy-control","title":"Chapter 2: Controlling Robots with rclpy","description":"rclpy is the official Python client library for ROS 2. It allows you to write ROS 2 nodes in Python and interact with the entire ROS 2 graph.","source":"@site/docs/module-1/chapter-2-rclpy-control.md","sourceDirName":"module-1","slug":"/module-1/chapter-2-rclpy-control","permalink":"/docs/module-1/chapter-2-rclpy-control","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-1/chapter-2-rclpy-control.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Core ROS 2 Concepts","permalink":"/docs/module-1/chapter-1-core-concepts"},"next":{"title":"Chapter 3: URDF Fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals"}},{"id":"module-1/chapter-3-urdf-fundamentals","title":"Chapter 3: URDF Fundamentals","description":"The Unified Robot Description Format (URDF) is an XML format used in ROS to describe all elements of a robot model. This includes the robot's links, joints, sensors, and their physical properties.","source":"@site/docs/module-1/chapter-3-urdf-fundamentals.md","sourceDirName":"module-1","slug":"/module-1/chapter-3-urdf-fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-1/chapter-3-urdf-fundamentals.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Controlling Robots with rclpy","permalink":"/docs/module-1/chapter-2-rclpy-control"},"next":{"title":"Chapter 4: Simple Humanoid Joint Control Project","permalink":"/docs/module-1/chapter-4-joint-control-project"}},{"id":"module-1/chapter-4-joint-control-project","title":"Chapter 4: Simple Humanoid Joint Control Project","description":"This project brings together all the concepts from the previous chapters to create a simple joint control project for our humanoid robot.","source":"@site/docs/module-1/chapter-4-joint-control-project.md","sourceDirName":"module-1","slug":"/module-1/chapter-4-joint-control-project","permalink":"/docs/module-1/chapter-4-joint-control-project","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-1/chapter-4-joint-control-project.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: URDF Fundamentals","permalink":"/docs/module-1/chapter-3-urdf-fundamentals"},"next":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"}},{"id":"module-2/chapter-1-gazebo-physics","title":"Chapter 1: Gazebo Physics","description":"This chapter covers the fundamental concepts of physics simulation within Gazebo.","source":"@site/docs/module-2/chapter-1-gazebo-physics.md","sourceDirName":"module-2","slug":"/module-2/chapter-1-gazebo-physics","permalink":"/docs/module-2/chapter-1-gazebo-physics","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-2/chapter-1-gazebo-physics.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Simple Humanoid Joint Control Project","permalink":"/docs/module-1/chapter-4-joint-control-project"},"next":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"}},{"id":"module-2/chapter-2-unity-digital-twin","title":"Chapter 2: Building a Unity Digital Twin","description":"Unity is a powerful cross-platform game engine that can be used to create high-fidelity digital twins for robotics. A digital twin in Unity allows for realistic rendering, complex animations, and interactive human-robot experiences.","source":"@site/docs/module-2/chapter-2-unity-digital-twin.md","sourceDirName":"module-2","slug":"/module-2/chapter-2-unity-digital-twin","permalink":"/docs/module-2/chapter-2-unity-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-2/chapter-2-unity-digital-twin.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo Physics","permalink":"/docs/module-2/chapter-1-gazebo-physics"},"next":{"title":"Chapter 3: Sensor Simulation","permalink":"/docs/module-2/chapter-3-sensor-simulation"}},{"id":"module-2/chapter-3-sensor-simulation","title":"Chapter 3: Sensor Simulation","description":"Simulating robot sensors is crucial for developing and testing perception and control algorithms without the need for expensive physical hardware. This chapter covers the principles behind simulating common sensors like LiDAR, Depth Cameras, and IMUs.","source":"@site/docs/module-2/chapter-3-sensor-simulation.md","sourceDirName":"module-2","slug":"/module-2/chapter-3-sensor-simulation","permalink":"/docs/module-2/chapter-3-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-2/chapter-3-sensor-simulation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Building a Unity Digital Twin","permalink":"/docs/module-2/chapter-2-unity-digital-twin"},"next":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"}},{"id":"module-3-isaac/chapter-1-isaac-sim-fundamentals","title":"Chapter 1: Isaac Sim Fundamentals","description":"1.1 Introduction to Isaac Sim","source":"@site/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-1-isaac-sim-fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensor Simulation","permalink":"/docs/module-2/chapter-3-sensor-simulation"},"next":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"}},{"id":"module-3-isaac/chapter-2-isaac-ros-vslam-perception","title":"Chapter 2: Isaac ROS VSLAM + Perception","description":"2.1 Introduction to Isaac ROS","source":"@site/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-2-isaac-ros-vslam-perception","permalink":"/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Isaac Sim Fundamentals","permalink":"/docs/module-3-isaac/chapter-1-isaac-sim-fundamentals"},"next":{"title":"Chapter 3: Nav2 Path Planning for Humanoids","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning"}},{"id":"module-3-isaac/chapter-3-nav2-humanoid-planning","title":"Chapter 3: Nav2 Path Planning for Humanoids","description":"3.1 Introduction to Nav2","source":"@site/docs/module-3-isaac/chapter-3-nav2-humanoid-planning.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-3-nav2-humanoid-planning","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-3-isaac/chapter-3-nav2-humanoid-planning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Isaac ROS VSLAM + Perception","permalink":"/docs/module-3-isaac/chapter-2-isaac-ros-vslam-perception"},"next":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"}},{"id":"module-3-isaac/chapter-4-isaac-sim-ros-workflow","title":"Chapter 4: Isaac Sim → Isaac ROS Workflow","description":"4.1 Introduction to Isaac Sim and Isaac ROS Integration","source":"@site/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-4-isaac-sim-ros-workflow","permalink":"/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-3-isaac/chapter-4-isaac-sim-ros-workflow.md","tags":[],"version":"current","frontMatter":{}},{"id":"module-4-vla/chapter-1-voice-to-action","title":"Chapter 1: Voice-to-Action","description":"This chapter explores the fundamental concepts behind converting a spoken command into a robotic action. This voice-to-action pipeline is a cornerstone of modern human-robot interaction, enabling intuitive control of complex systems.","source":"@site/docs/module-4-vla/chapter-1-voice-to-action.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-1-voice-to-action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-4-vla/chapter-1-voice-to-action.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 1: Voice-to-Action"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Nav2 Path Planning for Humanoids","permalink":"/docs/module-3-isaac/chapter-3-nav2-humanoid-planning"},"next":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"}},{"id":"module-4-vla/chapter-2-cognitive-planning","title":"Chapter 2: Cognitive Planning","description":"Cognitive planning is the \"brain\" of the autonomous robot. It involves taking a high-level, often abstract, goal and breaking it down into a concrete sequence of actions that the robot can execute. Large Language Models (LLMs) have emerged as a powerful tool for this task.","source":"@site/docs/module-4-vla/chapter-2-cognitive-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-2-cognitive-planning","permalink":"/docs/module-4-vla/chapter-2-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-4-vla/chapter-2-cognitive-planning.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 2: Cognitive Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Voice-to-Action","permalink":"/docs/module-4-vla/chapter-1-voice-to-action"},"next":{"title":"Chapter 3: Capstone Overview","permalink":"/docs/module-4-vla/chapter-3-capstone-overview"}},{"id":"module-4-vla/chapter-3-capstone-overview","title":"Chapter 3: Capstone Overview","description":"This chapter provides a high-level overview of how the concepts from the previous chapters—voice-to-action and cognitive planning—come together in a complete, autonomous humanoid robotics workflow. This is the \"capstone\" view that illustrates the full end-to-end system.","source":"@site/docs/module-4-vla/chapter-3-capstone-overview.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-3-capstone-overview","permalink":"/docs/module-4-vla/chapter-3-capstone-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/LAIBAMUSHARAF45/Hackathon-book/docs/module-4-vla/chapter-3-capstone-overview.md","tags":[],"version":"current","frontMatter":{"title":"Chapter 3: Capstone Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Cognitive Planning","permalink":"/docs/module-4-vla/chapter-2-cognitive-planning"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: ROS 2 Fundamentals","link":{"type":"doc","id":"module-1/chapter-1-core-concepts"},"items":[{"type":"doc","id":"module-1/chapter-1-core-concepts"},{"type":"doc","id":"module-1/chapter-2-rclpy-control"},{"type":"doc","id":"module-1/chapter-3-urdf-fundamentals"},{"type":"doc","id":"module-1/chapter-4-joint-control-project"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin Simulation","link":{"type":"doc","id":"module-2/chapter-1-gazebo-physics"},"items":[{"type":"doc","id":"module-2/chapter-1-gazebo-physics"},{"type":"doc","id":"module-2/chapter-2-unity-digital-twin"},{"type":"doc","id":"module-2/chapter-3-sensor-simulation"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","link":{"type":"doc","id":"module-3-isaac/chapter-1-isaac-sim-fundamentals"},"items":[{"type":"doc","id":"module-3-isaac/chapter-1-isaac-sim-fundamentals"},{"type":"doc","id":"module-3-isaac/chapter-2-isaac-ros-vslam-perception"},{"type":"doc","id":"module-3-isaac/chapter-3-nav2-humanoid-planning"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action","link":{"type":"doc","id":"module-4-vla/chapter-1-voice-to-action"},"items":[{"type":"doc","id":"module-4-vla/chapter-1-voice-to-action"},{"type":"doc","id":"module-4-vla/chapter-2-cognitive-planning"},{"type":"doc","id":"module-4-vla/chapter-3-capstone-overview"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}